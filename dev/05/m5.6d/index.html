<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>m5.6d · DynamicHMCModels.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link href="../../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>DynamicHMCModels.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../../intro/">Home</a></li><li><span class="toctext">Chapter 02</span><ul><li><a class="toctext" href="../../02/m2.1d/">m2.1d</a></li></ul></li><li><span class="toctext">Chapter 04</span><ul><li><a class="toctext" href="../../04/m4.1d/">m4.1d</a></li><li><a class="toctext" href="../../04/m4.2d/">m4.2d</a></li><li><a class="toctext" href="../../04/m4.5d/">m4.5d</a></li></ul></li><li><span class="toctext">Chapter 05</span><ul><li><a class="toctext" href="../m5.1d/">m5.1d</a></li><li><a class="toctext" href="../m5.1d1/">m5.1d1</a></li><li><a class="toctext" href="../m5.3d/">m5.3d</a></li><li class="current"><a class="toctext" href>m5.6d</a><ul class="internal"></ul></li></ul></li><li><span class="toctext">Chapter 08</span><ul><li><a class="toctext" href="../../08/m8.1d/">m8.1d</a></li></ul></li><li><span class="toctext">Chapter 10</span><ul><li><a class="toctext" href="../../10/m10.02d/">m10.02d</a></li><li><a class="toctext" href="../../10/m10.02d1/">m10.02d1</a></li><li><a class="toctext" href="../../10/m10.04d/">m10.04d</a></li></ul></li><li><span class="toctext">Chapter 12</span><ul><li><a class="toctext" href="../../12/m12.6d/">m12.6d</a></li><li><a class="toctext" href="../../12/m12.6d1/">m12.6d1</a></li></ul></li><li><a class="toctext" href="../../">Functions</a></li></ul></nav><article id="docs"><header><nav><ul><li>Chapter 05</li><li><a href>m5.6d</a></li></ul><a class="edit-page" href="https://github.com/StatisticalRethinkingJulia/DynamicHMCModels.jl/blob/master/scripts/05/m5.6d.jl"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>m5.6d</span><a class="fa fa-bars" href="#"></a></div></header><p>Load Julia packages (libraries) needed  for the snippets in chapter 0</p><div><pre><code class="language-julia">using DynamicHMCModels</code></pre></div><p>CmdStan uses a tmp directory to store the output of cmdstan</p><div><pre><code class="language-julia">ProjDir = rel_path_d(&quot;..&quot;, &quot;scripts&quot;, &quot;05&quot;)
cd(ProjDir)</code></pre></div><p>Read the milk data</p><div><pre><code class="language-julia">wd = CSV.read(rel_path(&quot;..&quot;, &quot;data&quot;, &quot;milk.csv&quot;), delim=&#39;;&#39;)
df = convert(DataFrame, wd);
dcc = filter(row -&gt; !(row[:neocortex_perc] == &quot;NA&quot;), df)
dcc[:kcal_per_g] = convert(Vector{Float64}, dcc[:kcal_per_g])
dcc[:log_mass] = log.(convert(Vector{Float64}, dcc[:mass]))</code></pre><pre><code class="language-none">17-element Array{Float64,1}:
  0.6678293725756554
  1.6582280766035324
  1.6808279085207734
  0.9202827531436925
 -0.3856624808119846
 -2.120263536200091
 -0.7550225842780328
 -1.1394342831883648
  0.4382549309311553
  1.1755733298042381
  2.509599262378372
  1.6808279085207734
  3.5689691574413787
  4.374876130645041
  3.70721041079866
  3.4998353515591547
  4.006423680849631</code></pre></div><p>Show first 5 rows</p><div><pre><code class="language-julia">first(dcc[[3, 7, 9]], 5)</code></pre><table class="data-frame"><thead><tr><th></th><th>kcal_per_g</th><th>mass</th><th>log_mass</th></tr><tr><th></th><th>Float64</th><th>Float64⍰</th><th>Float64</th></tr></thead><tbody><p>5 rows × 3 columns</p><tr><th>1</th><td>0.49</td><td>1.95</td><td>0.667829</td></tr><tr><th>2</th><td>0.47</td><td>5.25</td><td>1.65823</td></tr><tr><th>3</th><td>0.56</td><td>5.37</td><td>1.68083</td></tr><tr><th>4</th><td>0.89</td><td>2.51</td><td>0.920283</td></tr><tr><th>5</th><td>0.92</td><td>0.68</td><td>-0.385662</td></tr></tbody></table></div><p>Define the model struct</p><div><pre><code class="language-julia">struct m_5_6{TY &lt;: AbstractVector, TX &lt;: AbstractMatrix}
    &quot;Observations.&quot;
    y::TY
    &quot;Covariates&quot;
    X::TX
end</code></pre></div><p>Make the type callable with the parameters <em>as a single argument</em>.</p><div><pre><code class="language-julia">function (problem::m_5_6)(θ)
    @unpack y, X, = problem   # extract the data
    @unpack β, σ = θ            # works on the named tuple too
    ll = 0.0
    ll += logpdf(Normal(0, 100), X[1]) # a = X[1]
    ll += logpdf(Normal(0, 1), X[2]) # b1 = X[2]
    ll += logpdf(TDist(1.0), σ)
    ll += loglikelihood(Normal(0, σ), y .- X*β)
    ll
end</code></pre></div><p>Instantiate the model with data and inits.</p><div><pre><code class="language-julia">N = size(dcc, 1)
X = hcat(ones(N), dcc[:log_mass]);
y = dcc[:kcal_per_g]
p = m_5_6(y, X);
p((β = [1.0, 2.0], σ = 1.0))</code></pre><pre><code class="language-none">-242.8761844035513</code></pre></div><p>Write a function to return properly dimensioned transformation.</p><div><pre><code class="language-julia">problem_transformation(p::m_5_6) =
    as((β = as(Array, size(p.X, 2)), σ = asℝ₊))</code></pre></div><p>Wrap the problem with a transformation, then use Flux for the gradient.</p><div><pre><code class="language-julia">P = TransformedLogDensity(problem_transformation(p), p)
∇P = LogDensityRejectErrors(ADgradient(:ForwardDiff, P));</code></pre><pre><code class="language-none">LogDensityRejectErrors{LogDensityProblems.ForwardDiffLogDensity{TransformedLogDensity{TransformVariables.TransformNamedTuple{(:β, :σ),Tuple{TransformVariables.ArrayTransform{TransformVariables.Identity,1},TransformVariables.ShiftedExp{true,Float64}}},Main.ex-m5.6d.m_5_6{Array{Float64,1},Array{Float64,2}}},ForwardDiff.GradientConfig{ForwardDiff.Tag{getfield(LogDensityProblems, Symbol(&quot;##3#4&quot;)){TransformedLogDensity{TransformVariables.TransformNamedTuple{(:β, :σ),Tuple{TransformVariables.ArrayTransform{TransformVariables.Identity,1},TransformVariables.ShiftedExp{true,Float64}}},Main.ex-m5.6d.m_5_6{Array{Float64,1},Array{Float64,2}}}},Float64},Float64,3,Array{ForwardDiff.Dual{ForwardDiff.Tag{getfield(LogDensityProblems, Symbol(&quot;##3#4&quot;)){TransformedLogDensity{TransformVariables.TransformNamedTuple{(:β, :σ),Tuple{TransformVariables.ArrayTransform{TransformVariables.Identity,1},TransformVariables.ShiftedExp{true,Float64}}},Main.ex-m5.6d.m_5_6{Array{Float64,1},Array{Float64,2}}}},Float64},Float64,3},1}}}}(ForwardDiff AD wrapper for TransformedLogDensity of dimension 3, w/ chunk size 3)</code></pre></div><p>Tune and sample.</p><div><pre><code class="language-julia">chain, NUTS_tuned = NUTS_init_tune_mcmc(∇P, 1000);</code></pre><pre><code class="language-none">MCMC, adapting ϵ (75 steps)
0.0014 s/step ...done
MCMC, adapting ϵ (25 steps)
0.0079 s/step ...done
MCMC, adapting ϵ (50 steps)
0.0023 s/step ...done
MCMC, adapting ϵ (100 steps)
2.8e-5 s/step ...done
MCMC, adapting ϵ (200 steps)
8.0e-5 s/step ...done
MCMC, adapting ϵ (400 steps)
2.2e-5 s/step ...done
MCMC, adapting ϵ (50 steps)
3.0e-5 s/step ...done
MCMC (1000 steps)
3.3e-5 s/step ...done
(NUTS_Transition{Array{Float64,1},Float64}[NUTS_Transition{Array{Float64,1},Float64}([0.669295, -0.0167543, -1.91335], -4.28667, 3, DoubledTurn, 0.894918, 7), NUTS_Transition{Array{Float64,1},Float64}([0.719694, -0.0453762, -1.72636], -4.24915, 3, DoubledTurn, 0.871763, 7), NUTS_Transition{Array{Float64,1},Float64}([0.790515, -0.0486976, -1.95899], -5.22771, 2, DoubledTurn, 0.84242, 3), NUTS_Transition{Array{Float64,1},Float64}([0.682193, -0.0295068, -1.52533], -5.35338, 2, DoubledTurn, 1.0, 3), NUTS_Transition{Array{Float64,1},Float64}([0.703312, -0.0148548, -1.83871], -3.99811, 3, DoubledTurn, 0.999308, 7), NUTS_Transition{Array{Float64,1},Float64}([0.737176, -0.0443957, -1.76714], -4.33738, 2, DoubledTurn, 0.883035, 3), NUTS_Transition{Array{Float64,1},Float64}([0.74881, -0.0162087, -1.97224], -5.70178, 2, DoubledTurn, 0.798403, 3), NUTS_Transition{Array{Float64,1},Float64}([0.702606, -0.00670268, -1.97614], -5.78099, 2, DoubledTurn, 1.0, 3), NUTS_Transition{Array{Float64,1},Float64}([0.697545, -0.00679756, -1.84433], -4.54231, 2, DoubledTurn, 1.0, 3), NUTS_Transition{Array{Float64,1},Float64}([0.691622, -0.0023955, -1.90056], -4.29364, 1, DoubledTurn, 0.861816, 1)  …  NUTS_Transition{Array{Float64,1},Float64}([0.702179, -0.0386022, -1.53474], -5.71148, 2, DoubledTurn, 1.0, 3), NUTS_Transition{Array{Float64,1},Float64}([0.707351, -0.0296917, -1.33055], -5.74913, 2, DoubledTurn, 0.900922, 3), NUTS_Transition{Array{Float64,1},Float64}([0.708509, -0.0461613, -1.52945], -6.95765, 3, DoubledTurn, 0.965929, 7), NUTS_Transition{Array{Float64,1},Float64}([0.701488, -0.0136692, -1.99075], -4.72261, 3, DoubledTurn, 0.988816, 7), NUTS_Transition{Array{Float64,1},Float64}([0.712609, -0.0571603, -1.39157], -6.45452, 3, DoubledTurn, 0.747054, 7), NUTS_Transition{Array{Float64,1},Float64}([0.698113, -0.00516553, -2.00913], -6.6036, 3, DoubledTurn, 0.966648, 7), NUTS_Transition{Array{Float64,1},Float64}([0.657008, -0.0264597, -1.7857], -5.4202, 2, DoubledTurn, 1.0, 3), NUTS_Transition{Array{Float64,1},Float64}([0.772556, -0.0418918, -1.89236], -4.17148, 2, DoubledTurn, 0.955852, 3), NUTS_Transition{Array{Float64,1},Float64}([0.632657, -0.0211305, -1.52083], -5.5511, 3, DoubledTurn, 0.889014, 7), NUTS_Transition{Array{Float64,1},Float64}([0.718163, -0.0272561, -1.40744], -5.92204, 3, DoubledTurn, 0.946046, 7)], NUTS sampler in 3 dimensions
  stepsize (ϵ) ≈ 0.654
  maximum depth = 10
  Gaussian kinetic energy, √diag(M⁻¹): [0.0607413, 0.0250486, 0.207985]
)</code></pre></div><p>We use the transformation to obtain the posterior from the chain.</p><div><pre><code class="language-julia">posterior = TransformVariables.transform.(Ref(problem_transformation(p)), get_position.(chain));
posterior[1:5]</code></pre><pre><code class="language-none">5-element Array{NamedTuple{(:β, :σ),Tuple{Array{Float64,1},Float64}},1}:
 (β = [0.669295, -0.0167543], σ = 0.1475844908232269)
 (β = [0.719694, -0.0453762], σ = 0.1779309336002884)
 (β = [0.790515, -0.0486976], σ = 0.1410007021090529)
 (β = [0.682193, -0.0295068], σ = 0.21754966929445724)
 (β = [0.703312, -0.0148548], σ = 0.1590231121001086)</code></pre></div><p>Extract the parameter posterior means: <code>β</code>,</p><div><pre><code class="language-julia">posterior_β = mean(first, posterior)</code></pre><pre><code class="language-none">2-element Array{Float64,1}:
  0.7061539577335777
 -0.03289877550612464</code></pre></div><p>then <code>σ</code>:</p><div><pre><code class="language-julia">posterior_σ = mean(last, posterior)</code></pre><pre><code class="language-none">0.18165894275110117</code></pre></div><p>Effective sample sizes (of untransformed draws)</p><div><pre><code class="language-julia">ess = mapslices(effective_sample_size,
                get_position_matrix(chain); dims = 1)</code></pre></div><p>NUTS-specific statistics</p><div><pre><code class="language-julia">NUTS_statistics(chain)</code></pre><pre><code class="language-none">Hamiltonian Monte Carlo sample of length 1000
  acceptance rate mean: 0.91, min/25%/median/75%/max: 0.02 0.87 0.95 0.99 1.0
  termination: AdjacentTurn =&gt; 14% DoubledTurn =&gt; 86%
  depth: 1 =&gt; 4% 2 =&gt; 51% 3 =&gt; 43% 4 =&gt; 1% 5 =&gt; 0%</code></pre></div><p>cmdstan result</p><div><pre><code class="language-julia">cmdstan_result = &quot;
Iterations = 1:1000
Thinning interval = 1
Chains = 1,2,3,4
Samples per chain = 1000

Empirical Posterior Estimates:
          Mean         SD        Naive SE       MCSE      ESS
    a  0.70472876 0.057040655 0.00090189195 0.0011398893 1000
   bm -0.03150330 0.023642759 0.00037382484 0.0004712342 1000
sigma  0.18378372 0.039212805 0.00062000888 0.0011395979 1000

Quantiles:
          2.5%       25.0%       50.0%        75.0%       97.5%
    a  0.59112968  0.66848775  0.70444950  0.741410500 0.81915225
   bm -0.07729257 -0.04708425 -0.03104865 -0.015942925 0.01424901
sigma  0.12638780  0.15605950  0.17800600  0.204319250 0.27993590
&quot;;</code></pre><pre><code class="language-none">&quot;\nIterations = 1:1000\nThinning interval = 1\nChains = 1,2,3,4\nSamples per chain = 1000\n\nEmpirical Posterior Estimates:\n          Mean         SD        Naive SE       MCSE      ESS\n    a  0.70472876 0.057040655 0.00090189195 0.0011398893 1000\n   bm -0.03150330 0.023642759 0.00037382484 0.0004712342 1000\nsigma  0.18378372 0.039212805 0.00062000888 0.0011395979 1000\n\nQuantiles:\n          2.5%       25.0%       50.0%        75.0%       97.5%\n    a  0.59112968  0.66848775  0.70444950  0.741410500 0.81915225\n   bm -0.07729257 -0.04708425 -0.03104865 -0.015942925 0.01424901\nsigma  0.12638780  0.15605950  0.17800600  0.204319250 0.27993590\n&quot;</code></pre></div><p>Extract the parameter posterior means: <code>[β, σ]</code>,</p><div><pre><code class="language-julia">[posterior_β, posterior_σ]</code></pre><pre><code class="language-none">2-element Array{Any,1}:
  [0.706154, -0.0328988]
 0.18165894275110117</code></pre></div><p>End of <code>05/5.6d.jl</code></p><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p><footer><hr/><a class="previous" href="../m5.3d/"><span class="direction">Previous</span><span class="title">m5.3d</span></a><a class="next" href="../../08/m8.1d/"><span class="direction">Next</span><span class="title">m8.1d</span></a></footer></article></body></html>
