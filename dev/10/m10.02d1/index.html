<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>m10.02d1 · DynamicHMCModels.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link href="../../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>DynamicHMCModels.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../../intro/">Home</a></li><li><span class="toctext">Chapter 02</span><ul><li><a class="toctext" href="../../02/m2.1d/">m2.1d</a></li></ul></li><li><span class="toctext">Chapter 04</span><ul><li><a class="toctext" href="../../04/m4.1d/">m4.1d</a></li><li><a class="toctext" href="../../04/m4.2d/">m4.2d</a></li><li><a class="toctext" href="../../04/m4.5d/">m4.5d</a></li></ul></li><li><span class="toctext">Chapter 05</span><ul><li><a class="toctext" href="../../05/m5.1d/">m5.1d</a></li><li><a class="toctext" href="../../05/m5.1d1/">m5.1d1</a></li><li><a class="toctext" href="../../05/m5.3d/">m5.3d</a></li><li><a class="toctext" href="../../05/m5.6d/">m5.6d</a></li></ul></li><li><span class="toctext">Chapter 08</span><ul><li><a class="toctext" href="../../08/m8.1d/">m8.1d</a></li></ul></li><li><span class="toctext">Chapter 10</span><ul><li><a class="toctext" href="../m10.02d/">m10.02d</a></li><li class="current"><a class="toctext" href>m10.02d1</a><ul class="internal"></ul></li><li><a class="toctext" href="../m10.04d/">m10.04d</a></li><li><a class="toctext" href="../m10.04d1/">m10.04d1</a></li><li><a class="toctext" href="../m10.04d2/">m10.04d2</a></li></ul></li><li><span class="toctext">Chapter 12</span><ul><li><a class="toctext" href="../../12/m12.6d/">m12.6d</a></li><li><a class="toctext" href="../../12/m12.6d1/">m12.6d1</a></li><li><a class="toctext" href="../../12/m12.6d2/">m12.6d2</a></li></ul></li><li><a class="toctext" href="../../">Functions</a></li></ul></nav><article id="docs"><header><nav><ul><li>Chapter 10</li><li><a href>m10.02d1</a></li></ul><a class="edit-page" href="https://github.com/StatisticalRethinkingJulia/DynamicHMCModels.jl/blob/master/scripts/10/m10.02d1.jl"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>m10.02d1</span><a class="fa fa-bars" href="#"></a></div></header><p>Load Julia packages (libraries) needed  for the snippets in chapter 0</p><pre><code class="language-julia">using DynamicHMCModels, Optim</code></pre><h3><a class="nav-anchor" id="snippet-10.4-1" href="#snippet-10.4-1">snippet 10.4</a></h3><pre><code class="language-julia">d = CSV.read(rel_path(&quot;..&quot;, &quot;data&quot;, &quot;chimpanzees.csv&quot;), delim=&#39;;&#39;);
df = convert(DataFrame, d);
df[:pulled_left] = convert(Array{Int64}, df[:pulled_left])
df[:prosoc_left] = convert(Array{Int64}, df[:prosoc_left])
first(df, 5)

struct m_10_02d{TY &lt;: AbstractVector, TX &lt;: AbstractMatrix}
    &quot;Observations.&quot;
    y::TY
    &quot;Covariates&quot;
    X::TX
    &quot;Number of observations&quot;
    N::Int
end</code></pre><p>Make the type callable with the parameters <em>as a single argument</em>.</p><pre><code class="language-julia">function (problem::m_10_02d)(θ)
    @unpack y, X, N = problem   # extract the data
    @unpack β = trans(θ)  # works on the named tuple too
    ll = 0.0
    ll += sum(logpdf.(Normal(0, 10), β)) # a &amp; bp
    ll += sum([loglikelihood(Binomial(1, logistic(dot(X[i, :], β))), [y[i]]) for i in 1:N])
    ll
end</code></pre><p>Instantiate the model with data and inits.</p><pre><code class="language-julia">N = size(df, 1)
X = hcat(ones(Int64, N), df[:prosoc_left]);
y = df[:pulled_left]
p = m_10_02d(y, X, N);</code></pre><pre><code class="language-none">Main.ex-m10.02d1.m_10_02d{Array{Int64,1},Array{Int64,2}}([0, 1, 0, 0, 1, 1, 0, 0, 0, 0  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1 0; 1 0; … ; 1 0; 1 0], 504)</code></pre><p>Function convert from a single vector of parms to parks NamedTuple</p><pre><code class="language-julia">trans = as( (β = as(Array, size(p.X, 2)), ));

γ =  (β = [0.5, 1.0],)
θ = inverse(trans, γ)
p(θ)</code></pre><pre><code class="language-none">-371.672843317438</code></pre><p>Maximum<em>a</em>postrior</p><pre><code class="language-julia">x0 = θ;
lower = [-1.0, -1.0];
upper = [1.0, 2.0];
ll(x) = -p(x)

inner_optimizer = GradientDescent()

optimize(ll, lower, upper, x0, Fminbox(inner_optimizer))</code></pre><pre><code class="language-none">Results of Optimization Algorithm
 * Algorithm: Fminbox with Gradient Descent
 * Starting Point: [0.5,1.0]
 * Minimizer: [0.047708983716678,0.5573080392418944]
 * Minimum: 3.446925e+02
 * Iterations: 4
 * Convergence: true
   * |x - x&#39;| ≤ 0.0e+00: false 
     |x - x&#39;| = 5.99e-09 
   * |f(x) - f(x&#39;)| ≤ 0.0e+00 |f(x)|: true
     |f(x) - f(x&#39;)| = 0.00e+00 |f(x)|
   * |g(x)| ≤ 1.0e-08: true 
     |g(x)| = 4.69e-09 
   * Stopped by an increasing objective: true
   * Reached Maximum Number of Iterations: false
 * Objective Calls: 548
 * Gradient Calls: 548</code></pre><p>Write a function to return properly dimensioned transformation.</p><pre><code class="language-julia">problem_transformation(p::m_10_02d) =</code></pre><p>as( (β = as(Array, size(p.X, 2)), ) )</p><pre><code class="language-julia">      as( Vector, size(p.X, 2))</code></pre><p>Wrap the problem with a transformation, then use Flux for the gradient.</p><pre><code class="language-julia">P = TransformedLogDensity(problem_transformation(p), p)
∇P = LogDensityRejectErrors(ADgradient(:ForwardDiff, P));</code></pre><pre><code class="language-none">LogDensityRejectErrors{InvalidLogDensityException,LogDensityProblems.ForwardDiffLogDensity{TransformedLogDensity{TransformVariables.ArrayTransform{TransformVariables.Identity,1},Main.ex-m10.02d1.m_10_02d{Array{Int64,1},Array{Int64,2}}},ForwardDiff.GradientConfig{ForwardDiff.Tag{getfield(LogDensityProblems, Symbol(&quot;##1#2&quot;)){TransformedLogDensity{TransformVariables.ArrayTransform{TransformVariables.Identity,1},Main.ex-m10.02d1.m_10_02d{Array{Int64,1},Array{Int64,2}}}},Float64},Float64,2,Array{ForwardDiff.Dual{ForwardDiff.Tag{getfield(LogDensityProblems, Symbol(&quot;##1#2&quot;)){TransformedLogDensity{TransformVariables.ArrayTransform{TransformVariables.Identity,1},Main.ex-m10.02d1.m_10_02d{Array{Int64,1},Array{Int64,2}}}},Float64},Float64,2},1}}}}(ForwardDiff AD wrapper for TransformedLogDensity of dimension 2, w/ chunk size 2)</code></pre><p>Tune and sample.</p><pre><code class="language-julia">chain, NUTS_tuned = NUTS_init_tune_mcmc(∇P, 1000);</code></pre><pre><code class="language-none">(NUTS_Transition{Array{Float64,1},Float64}[NUTS_Transition{Array{Float64,1},Float64}([0.001623342061504971, 0.4864639173466965], -352.3060448135253, 1, DynamicHMC.AdjacentTurn, 0.6880362479234887, 3), NUTS_Transition{Array{Float64,1},Float64}([-0.015610914217756202, 0.7216922185361161], -346.83705502437056, 2, DynamicHMC.DoubledTurn, 0.861892175459034, 3), NUTS_Transition{Array{Float64,1},Float64}([0.19558268808389928, 0.4407637373984233], -346.843460686336, 2, DynamicHMC.DoubledTurn, 0.8382963500957302, 3), NUTS_Transition{Array{Float64,1},Float64}([-0.0432938769468041, 0.5554761040829466], -345.71457004705866, 3, DynamicHMC.AdjacentTurn, 0.9938915998819167, 11), NUTS_Transition{Array{Float64,1},Float64}([0.0601125531681484, 0.7531177903775593], -346.60102495060664, 2, DynamicHMC.DoubledTurn, 0.9059120336866653, 3), NUTS_Transition{Array{Float64,1},Float64}([-0.06289240588029729, 0.6767944075652697], -347.58977083478527, 2, DynamicHMC.DoubledTurn, 0.8785405167939633, 3), NUTS_Transition{Array{Float64,1},Float64}([-0.19967754189890075, 0.6697354693041359], -347.703570729385, 2, DynamicHMC.DoubledTurn, 0.7704925671558157, 3), NUTS_Transition{Array{Float64,1},Float64}([0.005906089036132017, 0.9244789423834032], -349.77682994997735, 2, DynamicHMC.AdjacentTurn, 0.9157962764304423, 7), NUTS_Transition{Array{Float64,1},Float64}([-0.041005692796887004, 0.6362719402348991], -350.2333632017319, 2, DynamicHMC.DoubledTurn, 0.8592704325572305, 3), NUTS_Transition{Array{Float64,1},Float64}([-0.08431722395900103, 0.956309626166937], -347.5408592732459, 2, DynamicHMC.DoubledTurn, 0.7936578147812384, 3)  …  NUTS_Transition{Array{Float64,1},Float64}([0.05353468688650939, 0.7279285362683076], -346.7507720368876, 3, DynamicHMC.AdjacentTurn, 0.9748653151139339, 15), NUTS_Transition{Array{Float64,1},Float64}([0.08262673696972811, 0.45336921614473324], -347.3453055569761, 1, DynamicHMC.AdjacentTurn, 0.85814675732059, 3), NUTS_Transition{Array{Float64,1},Float64}([0.20515064043860937, 0.24494982782847796], -350.39906824921314, 2, DynamicHMC.DoubledTurn, 0.5582725695756429, 3), NUTS_Transition{Array{Float64,1},Float64}([0.07580524300106456, 0.40009112482756193], -346.26281206180516, 2, DynamicHMC.DoubledTurn, 1.0, 3), NUTS_Transition{Array{Float64,1},Float64}([0.027823781913932054, 0.6328977966511086], -345.24566640223156, 5, DynamicHMC.DoubledTurn, 0.9980354853310662, 31), NUTS_Transition{Array{Float64,1},Float64}([-0.1251791063063187, 0.6985292987978464], -345.79853911552533, 2, DynamicHMC.DoubledTurn, 0.8836516764761364, 3), NUTS_Transition{Array{Float64,1},Float64}([0.16298018534207098, 0.4466425304313348], -345.7660775217482, 2, DynamicHMC.DoubledTurn, 0.9980669705322248, 3), NUTS_Transition{Array{Float64,1},Float64}([0.028587856792994998, 0.5470084544840008], -345.44962910524526, 2, DynamicHMC.DoubledTurn, 0.9574408070695801, 3), NUTS_Transition{Array{Float64,1},Float64}([0.029244007550659566, 0.576124721005493], -344.7390744779258, 2, DynamicHMC.AdjacentTurn, 0.9995064074691997, 7), NUTS_Transition{Array{Float64,1},Float64}([-0.01805210730131361, 0.56872286176921], -345.7581387052209, 2, DynamicHMC.DoubledTurn, 0.8793625403460847, 3)], NUTS sampler in 2 dimensions
  stepsize (ϵ) ≈ 0.775
  maximum depth = 10
  Gaussian kinetic energy, √diag(M⁻¹): [0.13857031852979534, 0.1872866306736713]
)</code></pre><p>We use the transformation to obtain the posterior from the chain.</p><pre><code class="language-julia">posterior = TransformVariables.transform.(Ref(problem_transformation(p)), get_position.(chain));
posterior[1:5]</code></pre><pre><code class="language-none">5-element Array{Array{Float64,1},1}:
 [0.001623342061504971, 0.4864639173466965] 
 [-0.015610914217756202, 0.7216922185361161]
 [0.19558268808389928, 0.4407637373984233]  
 [-0.0432938769468041, 0.5554761040829466]  
 [0.0601125531681484, 0.7531177903775593]   </code></pre><p>Extract the parameter posterior means: <code>β</code>,</p><pre><code class="language-julia">posterior_a = mean(first, posterior)
posterior_bp = mean(last, posterior)</code></pre><pre><code class="language-none">0.573312358180829</code></pre><p>Effective sample sizes (of untransformed draws)</p><pre><code class="language-julia">ess = mapslices(effective_sample_size, get_position_matrix(chain); dims = 1)
ess</code></pre><pre><code class="language-none">1×2 Array{Float64,2}:
 960.851  831.507</code></pre><p>NUTS-specific statistics</p><pre><code class="language-julia">NUTS_statistics(chain)</code></pre><pre><code class="language-none">Hamiltonian Monte Carlo sample of length 1000
  acceptance rate mean: 0.93, min/25%/median/75%/max: 0.53 0.89 0.96 0.99 1.0
  termination: AdjacentTurn =&gt; 38% DoubledTurn =&gt; 62%
  depth: 1 =&gt; 15% 2 =&gt; 61% 3 =&gt; 12% 4 =&gt; 9% 5 =&gt; 2% 6 =&gt; 2%
</code></pre><p>CmdStan result</p><pre><code class="language-julia">m_10_2s_result = &quot;
Iterations = 1:1000
Thinning interval = 1
Chains = 1,2,3,4
Samples per chain = 1000

Empirical Posterior Estimates:
      Mean        SD       Naive SE       MCSE      ESS
 a 0.05103234 0.12579086 0.0019889282 0.0035186307 1000
bp 0.55711212 0.18074275 0.0028577937 0.0040160451 1000

Quantiles:
       2.5%        25.0%       50.0%      75.0%      97.5%
 a -0.19755400 -0.029431425 0.05024655 0.12978825 0.30087758
bp  0.20803447  0.433720250 0.55340400 0.67960975 0.91466915
&quot;;</code></pre><pre><code class="language-none">&quot;\nIterations = 1:1000\nThinning interval = 1\nChains = 1,2,3,4\nSamples per chain = 1000\n\nEmpirical Posterior Estimates:\n      Mean        SD       Naive SE       MCSE      ESS\n a 0.05103234 0.12579086 0.0019889282 0.0035186307 1000\nbp 0.55711212 0.18074275 0.0028577937 0.0040160451 1000\n\nQuantiles:\n       2.5%        25.0%       50.0%      75.0%      97.5%\n a -0.19755400 -0.029431425 0.05024655 0.12978825 0.30087758\nbp  0.20803447  0.433720250 0.55340400 0.67960975 0.91466915\n&quot;</code></pre><p>Extract the parameter posterior means: <code>β</code>,</p><pre><code class="language-julia">[posterior_a, posterior_bp]</code></pre><pre><code class="language-none">2-element Array{Float64,1}:
 0.043696727587160436
 0.573312358180829   </code></pre><p>End of <code>10/m10.02d.jl</code></p><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p><footer><hr/><a class="previous" href="../m10.02d/"><span class="direction">Previous</span><span class="title">m10.02d</span></a><a class="next" href="../m10.04d/"><span class="direction">Next</span><span class="title">m10.04d</span></a></footer></article></body></html>
