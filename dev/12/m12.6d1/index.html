<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>m12.6d1 · DynamicHMCModels.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link href="../../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>DynamicHMCModels.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../../intro/">Home</a></li><li><span class="toctext">Chapter 02</span><ul><li><a class="toctext" href="../../02/m2.1d/">m2.1d</a></li></ul></li><li><span class="toctext">Chapter 04</span><ul><li><a class="toctext" href="../../04/m4.1d/">m4.1d</a></li><li><a class="toctext" href="../../04/m4.2d/">m4.2d</a></li><li><a class="toctext" href="../../04/m4.5d/">m4.5d</a></li></ul></li><li><span class="toctext">Chapter 05</span><ul><li><a class="toctext" href="../../05/m5.1d/">m5.1d</a></li><li><a class="toctext" href="../../05/m5.1d1/">m5.1d1</a></li><li><a class="toctext" href="../../05/m5.3d/">m5.3d</a></li><li><a class="toctext" href="../../05/m5.6d/">m5.6d</a></li></ul></li><li><span class="toctext">Chapter 08</span><ul><li><a class="toctext" href="../../08/m8.1d/">m8.1d</a></li></ul></li><li><span class="toctext">Chapter 10</span><ul><li><a class="toctext" href="../../10/m10.02d/">m10.02d</a></li><li><a class="toctext" href="../../10/m10.02d1/">m10.02d1</a></li><li><a class="toctext" href="../../10/m10.04d/">m10.04d</a></li></ul></li><li><span class="toctext">Chapter 12</span><ul><li><a class="toctext" href="../m12.6d/">m12.6d</a></li><li class="current"><a class="toctext" href>m12.6d1</a><ul class="internal"></ul></li></ul></li><li><a class="toctext" href="../../">Functions</a></li></ul></nav><article id="docs"><header><nav><ul><li>Chapter 12</li><li><a href>m12.6d1</a></li></ul><a class="edit-page" href="https://github.com/StatisticalRethinkingJulia/DynamicHMCModels.jl/blob/master/scripts/12/m12.6d1.jl"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>m12.6d1</span><a class="fa fa-bars" href="#"></a></div></header><div><pre><code class="language-julia">using DynamicHMCModels

ProjDir = rel_path_d(&quot;..&quot;, &quot;scripts&quot;, &quot;12&quot;)

df = CSV.read(rel_path( &quot;..&quot;, &quot;data&quot;,  &quot;Kline.csv&quot;), delim=&#39;;&#39;);
size(df) # Should be 10x5</code></pre><pre><code class="language-none">(10, 5)</code></pre></div><p>New col logpop, set log() for population data</p><div><pre><code class="language-julia">df[:society] = 1:10;
df[:logpop] = map((x) -&gt; log(x), df[:population]);
#df[:total_tools] = convert(Vector{Int64}, df[:total_tools])
first(df[[:total_tools, :logpop, :society]], 5)</code></pre><table class="data-frame"><thead><tr><th></th><th>total_tools</th><th>logpop</th><th>society</th></tr><tr><th></th><th>Int64⍰</th><th>Float64</th><th>Int64</th></tr></thead><tbody><p>5 rows × 3 columns</p><tr><th>1</th><td>13</td><td>7.00307</td><td>1</td></tr><tr><th>2</th><td>22</td><td>7.31322</td><td>2</td></tr><tr><th>3</th><td>24</td><td>8.18869</td><td>3</td></tr><tr><th>4</th><td>43</td><td>8.47449</td><td>4</td></tr><tr><th>5</th><td>33</td><td>8.90924</td><td>5</td></tr></tbody></table></div><p>Define problem data structure</p><div><pre><code class="language-julia">struct m_12_06d{TY &lt;: AbstractVector, TX &lt;: AbstractMatrix,
  TS &lt;: AbstractVector}
    &quot;Observations (total_tools).&quot;
    y::TY
    &quot;Covariates (logpop)&quot;
    X::TX
    &quot;Society&quot;
    S::TS
    &quot;Number of observations (10)&quot;
    N::Int
    &quot;Number of societies (also 10)&quot;
    N_societies::Int
end;</code></pre></div><p>Make the type callable with the parameters <em>as a single argument</em>.</p><div><pre><code class="language-julia">function (problem::m_12_06d)(θ)
    @unpack y, X, S, N, N_societies = problem   # extract the data
    @unpack β, α, s = trans(θ)  # β : a, bp, α : a_society, s
    σ = s[1]^2
    ll = 0.0
    ll += logpdf(Cauchy(0, 1), σ) # sigma
    ll += sum(logpdf.(Normal(0, σ), α)) # α[1:10]
    ll += logpdf.(Normal(0, 10), β[1]) # a
    ll += logpdf.(Normal(0, 1), β[2]) # bp
    ll += sum(
      [loglikelihood(Poisson(exp(α[S[i]] + dot(X[i, :], β))), [y[i]]) for i in 1:N]
    )
end</code></pre></div><p>Instantiate the model with data and inits.</p><div><pre><code class="language-julia">N = size(df, 1)
N_societies = length(unique(df[:society]))
X = hcat(ones(Int64, N), df[:logpop]);
S = df[:society];
y = df[:total_tools];
γ = (β = [1.0, 0.25], α = rand(Normal(0, 1), N_societies), s = [0.2]);
p = m_12_06d(y, X, S, N, N_societies);</code></pre><pre><code class="language-none">Main.ex-m12.6d1.m_12_06d{Array{Union{Missing, Int64},1},Array{Float64,2},Array{Int64,1}}(Union{Missing, Int64}[13, 22, 24, 43, 33, 19, 40, 28, 55, 71], [1.0 7.00307; 1.0 7.31322; … ; 1.0 9.76996; 1.0 12.5245], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 10, 10)</code></pre></div><p>Function convert from a single vector of parms to parks NamedTuple</p><div><pre><code class="language-julia">trans = as((β = as(Array, 2), α = as(Array, 10), s = as(Array, 1)));</code></pre><pre><code class="language-none">TransformVariables.TransformNamedTuple{(:β, :α, :s),Tuple{TransformVariables.ArrayTransform{TransformVariables.Identity,1},TransformVariables.ArrayTransform{TransformVariables.Identity,1},TransformVariables.ArrayTransform{TransformVariables.Identity,1}}}((TransformVariables.ArrayTransform{TransformVariables.Identity,1}(TransformVariables.Identity(), (2,)), TransformVariables.ArrayTransform{TransformVariables.Identity,1}(TransformVariables.Identity(), (10,)), TransformVariables.ArrayTransform{TransformVariables.Identity,1}(TransformVariables.Identity(), (1,))), 13)</code></pre></div><p>Define input parameter vector</p><div><pre><code class="language-julia">θ = inverse(trans, γ);
p(θ)</code></pre><pre><code class="language-none">-2183.123775409762</code></pre></div><p>Maximum<em>a</em>posterior</p><div><pre><code class="language-julia">using Optim

x0 = θ;
lower = vcat([0.0, 0.0], -3ones(10), [0.0]);
upper = vcat([2.0, 1.0], 3ones(10), [5.0]);
ll(x) = -p(x);

inner_optimizer = GradientDescent()

res = optimize(ll, lower, upper, x0, Fminbox(inner_optimizer));
res</code></pre><pre><code class="language-none">Results of Optimization Algorithm
 * Algorithm: Fminbox with Gradient Descent
 * Starting Point: [1.0,0.25, ...]
 * Minimizer: [1.0977196626836627,0.2630418179422197, ...]
 * Minimum: -1.353189e+02
 * Iterations: 1000
 * Convergence: false
   * |x - x&#39;| ≤ 0.0e+00: false
     |x - x&#39;| = 4.16e-11
   * |f(x) - f(x&#39;)| ≤ 0.0e+00 |f(x)|: false
     |f(x) - f(x&#39;)| = -4.60e-08 |f(x)|
   * |g(x)| ≤ 1.0e-08: false
     |g(x)| = 4.13e+05
   * Stopped by an increasing objective: false
   * Reached Maximum Number of Iterations: false
 * Objective Calls: 140963593
 * Gradient Calls: 140963593</code></pre></div><p>Minimum gives MAP estimate:</p><div><pre><code class="language-julia">Optim.minimizer(res)</code></pre><pre><code class="language-none">13-element Array{Float64,1}:
  1.0977196626836627
  0.2630418179422197
 -6.212434136724721e-13
  2.640195461133974e-13
 -6.082314756898181e-14
  1.969854195858811e-12
  4.64279801283323e-13
 -1.2426988297592253e-12
  1.1160589988290879e-12
 -5.695377464434605e-13
  2.368337149491513e-12
  1.534371238462784e-11
  7.80912529114998e-5</code></pre></div><p>Write a function to return properly dimensioned transformation.</p><div><pre><code class="language-julia">problem_transformation(p::m_12_06d) =
  as( Vector, length(θ) )</code></pre></div><p>Wrap the problem with a transformation, then use ForwardDiff for the gradient.</p><div><pre><code class="language-julia">P = TransformedLogDensity(problem_transformation(p), p)
∇P = LogDensityRejectErrors(ADgradient(:ForwardDiff, P));
#∇P = ADgradient(:ForwardDiff, P);</code></pre></div><p>Tune and sample.</p><div><pre><code class="language-julia">chain, NUTS_tuned = NUTS_init_tune_mcmc(∇P, 1000);</code></pre><pre><code class="language-none">MCMC, adapting ϵ (75 steps)
0.0065 s/step ...done
MCMC, adapting ϵ (25 steps)
0.0066 s/step ...done
MCMC, adapting ϵ (50 steps)
0.0081 s/step ...done
MCMC, adapting ϵ (100 steps)
0.0027 s/step ...done
MCMC, adapting ϵ (200 steps)
0.0016 s/step ...done
MCMC, adapting ϵ (400 steps)
0.00098 s/step ...done
MCMC, adapting ϵ (50 steps)
0.00078 s/step ...done
MCMC (1000 steps)
0.00078 s/step ...done
(NUTS_Transition{Array{Float64,1},Float64}[NUTS_Transition{Array{Float64,1},Float64}([0.445879, 0.318812, -0.0445322, 0.234673, 0.178343, 0.39582, 0.24185, -0.527, 0.412777, -0.264903, 0.581555, -0.253049, 0.528615], -46.6975, 4, DoubledTurn, 0.974875, 15), NUTS_Transition{Array{Float64,1},Float64}([1.93144, 0.174966, -0.369651, 0.0378739, -0.160755, 0.1855, -0.262008, -0.231455, 0.131897, -0.300171, 0.352977, 0.12025, 0.616292], -47.213, 4, DoubledTurn, 0.867473, 15), NUTS_Transition{Array{Float64,1},Float64}([1.25564, 0.2554, -0.225248, -0.00814139, -0.205874, 0.244247, -0.279703, -0.321932, -0.0575955, -0.450499, 0.139666, -0.147185, 0.507006], -39.9592, 4, DoubledTurn, 0.968557, 15), NUTS_Transition{Array{Float64,1},Float64}([1.32405, 0.239297, -0.323666, -0.0135642, -0.136783, 0.137657, 0.203596, -0.372207, 0.119225, 0.0397367, 0.196076, -0.120208, 0.450828], -39.9664, 4, DoubledTurn, 0.985723, 15), NUTS_Transition{Array{Float64,1},Float64}([1.38427, 0.225506, 0.13657, 0.203424, -0.0397839, 0.314557, 0.0857875, -0.095579, 0.0523083, -0.158748, 0.0647775, 0.107579, 0.413377], -41.4007, 4, DoubledTurn, 0.875138, 15), NUTS_Transition{Array{Float64,1},Float64}([1.26154, 0.257517, -0.114145, -0.0365538, -0.0606179, 0.0337503, -0.0509768, -0.292491, 0.0872409, -0.0997323, 0.0859886, -0.0878991, 0.366315], -39.6984, 4, DoubledTurn, 0.88771, 15), NUTS_Transition{Array{Float64,1},Float64}([0.892011, 0.267364, 0.0423738, 0.19298, 0.00507816, 0.0104282, -0.0412387, -0.0279911, 0.0116518, -0.0121239, 0.213716, 0.0196231, 0.28082], -37.3883, 4, DoubledTurn, 0.830655, 15), NUTS_Transition{Array{Float64,1},Float64}([1.22464, 0.243732, -0.190043, -0.145266, 0.0180873, 0.396496, 0.165813, -0.349578, 0.199084, 0.00527084, 0.243303, 0.00829271, 0.508723], -40.1884, 4, DoubledTurn, 0.947223, 15), NUTS_Transition{Array{Float64,1},Float64}([0.592628, 0.313612, -0.114435, 0.100174, -0.0238633, 0.416994, 0.162198, 0.114049, 0.046433, -0.131285, 0.165559, -0.070283, 0.485229], -42.9674, 4, DoubledTurn, 0.911515, 15), NUTS_Transition{Array{Float64,1},Float64}([1.28184, 0.256199, -0.308621, -0.349901, -0.111397, 0.406668, 0.171665, -0.336914, 0.0937814, -0.257522, -0.184749, -0.215915, 0.530683], -44.672, 4, DoubledTurn, 0.989941, 15)  …  NUTS_Transition{Array{Float64,1},Float64}([1.42446, 0.221322, -0.201128, 0.0894866, -0.168727, 0.224859, 0.111447, -0.256202, 0.213806, -0.169162, 0.120698, -0.0297571, 0.412232], -39.977, 4, DoubledTurn, 0.991932, 15), NUTS_Transition{Array{Float64,1},Float64}([1.56096, 0.20241, -0.281683, 0.0809808, -0.07132, 0.219741, 0.0214982, -0.272949, 0.107659, -0.226558, 0.409214, 0.0737985, 0.5128], -36.9475, 4, DoubledTurn, 0.966103, 15), NUTS_Transition{Array{Float64,1},Float64}([1.54041, 0.238445, -0.262984, -0.175843, 0.0582668, 0.00782949, -0.17196, -0.537173, 0.0573302, -0.30229, 0.138107, -0.129659, 0.502406], -40.0643, 4, DoubledTurn, 0.958129, 15), NUTS_Transition{Array{Float64,1},Float64}([2.05717, 0.158254, -0.897566, 0.0642825, -0.379247, 0.609261, 0.0781985, -0.709864, 0.0544726, 0.152752, 0.407223, 0.143717, 0.657439], -49.2571, 4, DoubledTurn, 0.973242, 15), NUTS_Transition{Array{Float64,1},Float64}([1.49187, 0.213498, 0.0425581, -0.226751, 0.202141, -0.0737994, 0.145365, -0.0689454, -0.0111761, -0.144766, 0.27175, 0.131048, 0.432892], -50.3074, 4, DoubledTurn, 0.988757, 15), NUTS_Transition{Array{Float64,1},Float64}([1.14896, 0.27841, -0.0431745, -0.167446, -0.0884062, 0.181503, -0.0191013, -0.357997, 0.10891, -0.410043, 0.0442871, -0.257296, 0.505814], -44.177, 3, DoubledTurn, 0.891386, 7), NUTS_Transition{Array{Float64,1},Float64}([0.50057, 0.31474, 0.418011, 0.0114981, 0.292466, 0.346909, 0.0312229, -0.164906, 0.275901, -0.265399, 0.150412, -0.271189, 0.477762], -43.6917, 4, DoubledTurn, 0.981407, 15), NUTS_Transition{Array{Float64,1},Float64}([2.15214, 0.165402, -1.0645, -0.0922828, -0.640381, 0.272937, -0.129465, -0.635003, 0.0059381, -0.21156, 0.354909, 0.134535, 0.626369], -46.7163, 4, DoubledTurn, 0.988164, 15), NUTS_Transition{Array{Float64,1},Float64}([0.677269, 0.298012, 0.222852, 0.039932, 0.215073, 0.375094, 0.140303, -0.143175, 0.19743, -0.155631, 0.209511, -0.122469, 0.510592], -45.5821, 4, DoubledTurn, 0.958446, 15), NUTS_Transition{Array{Float64,1},Float64}([1.52265, 0.2154, -0.35454, 0.260623, -0.0528438, 0.346035, 0.042001, -0.358438, 0.20787, -0.0859518, 0.408392, -0.0524281, 0.566227], -41.4507, 4, DoubledTurn, 0.980433, 15)], NUTS sampler in 13 dimensions
  stepsize (ϵ) ≈ 0.235
  maximum depth = 10
  Gaussian kinetic energy, √diag(M⁻¹): [0.739309, 0.0816943, 0.252151, 0.21469, 0.219651, 0.201388, 0.18738, 0.210218, 0.195886, 0.192716, 0.18727, 0.290627, 0.10676]
)</code></pre></div><p>We use the transformation to obtain the posterior from the chain.</p><div><pre><code class="language-julia">posterior = TransformVariables.transform.(Ref(problem_transformation(p)), get_position.(chain));
posterior[1:5]</code></pre><pre><code class="language-none">5-element Array{Array{Float64,1},1}:
 [0.445879, 0.318812, -0.0445322, 0.234673, 0.178343, 0.39582, 0.24185, -0.527, 0.412777, -0.264903, 0.581555, -0.253049, 0.528615]
 [1.93144, 0.174966, -0.369651, 0.0378739, -0.160755, 0.1855, -0.262008, -0.231455, 0.131897, -0.300171, 0.352977, 0.12025, 0.616292]
 [1.25564, 0.2554, -0.225248, -0.00814139, -0.205874, 0.244247, -0.279703, -0.321932, -0.0575955, -0.450499, 0.139666, -0.147185, 0.507006]
 [1.32405, 0.239297, -0.323666, -0.0135642, -0.136783, 0.137657, 0.203596, -0.372207, 0.119225, 0.0397367, 0.196076, -0.120208, 0.450828]
 [1.38427, 0.225506, 0.13657, 0.203424, -0.0397839, 0.314557, 0.0857875, -0.095579, 0.0523083, -0.158748, 0.0647775, 0.107579, 0.413377]</code></pre></div><p>Extract the parameter posterior means.</p><div><pre><code class="language-julia">posterior_β = mean(trans(posterior[i]).β for i in 1:length(posterior))
posterior_α = mean(trans(posterior[i]).α for i in 1:length(posterior))
posterior_σ = mean(trans(posterior[i]).s for i in 1:length(posterior))[1]^2</code></pre><pre><code class="language-none">0.269603230845692</code></pre></div><p>Effective sample sizes (of untransformed draws)</p><div><pre><code class="language-julia">ess = mapslices(effective_sample_size, get_position_matrix(chain); dims = 1)
ess</code></pre><pre><code class="language-none">1×13 Array{Float64,2}:
 880.423  870.227  803.99  605.962  …  873.923  828.527  1000.0  356.113</code></pre></div><p>NUTS-specific statistics</p><div><pre><code class="language-julia">NUTS_statistics(chain)</code></pre><pre><code class="language-none">Hamiltonian Monte Carlo sample of length 1000
  acceptance rate mean: 0.92, min/25%/median/75%/max: 0.14 0.89 0.96 0.99 1.0
  termination: AdjacentTurn =&gt; 4% DoubledTurn =&gt; 96%
  depth: 2 =&gt; 0% 3 =&gt; 9% 4 =&gt; 91%</code></pre></div><p>CmdStan result</p><div><pre><code class="language-julia">m_12_6_result = &quot;
Iterations = 1:1000
Thinning interval = 1
Chains = 1,2,3,4
Samples per chain = 1000

Empirical Posterior Estimates:
                            Mean                SD               Naive SE             MCSE            ESS
            a          1.076167468  0.7704872560 0.01218247319 0.0210530022 1000.000000
           bp         0.263056273  0.0823415805 0.00130193470 0.0022645077 1000.000000
  a_society.1   -0.191723568  0.2421382537 0.00382854195 0.0060563054 1000.000000
  a_society.2    0.054569029  0.2278506876 0.00360263570 0.0051693148 1000.000000
  a_society.3   -0.035935050  0.1926364647 0.00304584994 0.0039948433 1000.000000
  a_society.4    0.334355037  0.1929971201 0.00305155241 0.0063871707  913.029080
  a_society.5    0.049747513  0.1801287716 0.00284808595 0.0043631095 1000.000000
  a_society.6   -0.311903245  0.2096126337 0.00331426674 0.0053000536 1000.000000
  a_society.7    0.148637507  0.1744680594 0.00275858223 0.0047660246 1000.000000
  a_society.8   -0.164567976  0.1821341074 0.00287979309 0.0034297298 1000.000000
  a_society.9    0.277066965  0.1758237250 0.00278001719 0.0055844175  991.286501
 a_society.10   -0.094149204  0.2846206232 0.00450024719 0.0080735022 1000.000000
sigma_society    0.310352849  0.1374834682 0.00217380450 0.0057325226  575.187461
&quot;;</code></pre><pre><code class="language-none">&quot;\nIterations = 1:1000\nThinning interval = 1\nChains = 1,2,3,4\nSamples per chain = 1000\n\nEmpirical Posterior Estimates:\n                            Mean                SD               Naive SE             MCSE            ESS\n            a          1.076167468  0.7704872560 0.01218247319 0.0210530022 1000.000000\n           bp         0.263056273  0.0823415805 0.00130193470 0.0022645077 1000.000000\n  a_society.1   -0.191723568  0.2421382537 0.00382854195 0.0060563054 1000.000000\n  a_society.2    0.054569029  0.2278506876 0.00360263570 0.0051693148 1000.000000\n  a_society.3   -0.035935050  0.1926364647 0.00304584994 0.0039948433 1000.000000\n  a_society.4    0.334355037  0.1929971201 0.00305155241 0.0063871707  913.029080\n  a_society.5    0.049747513  0.1801287716 0.00284808595 0.0043631095 1000.000000\n  a_society.6   -0.311903245  0.2096126337 0.00331426674 0.0053000536 1000.000000\n  a_society.7    0.148637507  0.1744680594 0.00275858223 0.0047660246 1000.000000\n  a_society.8   -0.164567976  0.1821341074 0.00287979309 0.0034297298 1000.000000\n  a_society.9    0.277066965  0.1758237250 0.00278001719 0.0055844175  991.286501\n a_society.10   -0.094149204  0.2846206232 0.00450024719 0.0080735022 1000.000000\nsigma_society    0.310352849  0.1374834682 0.00217380450 0.0057325226  575.187461\n&quot;</code></pre></div><p>Show means</p><div><pre><code class="language-julia">[posterior_β, posterior_α, posterior_σ]</code></pre><pre><code class="language-none">3-element Array{Any,1}:
  [1.10299, 0.261583]
  [-0.19093, 0.0356628, -0.045205, 0.302812, 0.0466648, -0.306397, 0.133304, -0.164974, 0.252458, -0.0968798]
 0.269603230845692</code></pre></div><p>End of m12.6d1.jl</p><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p><footer><hr/><a class="previous" href="../m12.6d/"><span class="direction">Previous</span><span class="title">m12.6d</span></a><a class="next" href="../../"><span class="direction">Next</span><span class="title">Functions</span></a></footer></article></body></html>
