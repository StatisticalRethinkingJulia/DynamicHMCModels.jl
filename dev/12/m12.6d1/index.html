<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>m12.6d1 · DynamicHMCModels.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link href="../../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>DynamicHMCModels.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../../intro/">Home</a></li><li><span class="toctext">Chapter 02</span><ul><li><a class="toctext" href="../../02/m2.1d/">m2.1d</a></li></ul></li><li><span class="toctext">Chapter 04</span><ul><li><a class="toctext" href="../../04/m4.1d/">m4.1d</a></li><li><a class="toctext" href="../../04/m4.2d/">m4.2d</a></li><li><a class="toctext" href="../../04/m4.5d/">m4.5d</a></li></ul></li><li><span class="toctext">Chapter 05</span><ul><li><a class="toctext" href="../../05/m5.1d/">m5.1d</a></li><li><a class="toctext" href="../../05/m5.1d1/">m5.1d1</a></li><li><a class="toctext" href="../../05/m5.3d/">m5.3d</a></li><li><a class="toctext" href="../../05/m5.6d/">m5.6d</a></li></ul></li><li><span class="toctext">Chapter 08</span><ul><li><a class="toctext" href="../../08/m8.1d/">m8.1d</a></li></ul></li><li><span class="toctext">Chapter 10</span><ul><li><a class="toctext" href="../../10/m10.02d/">m10.02d</a></li><li><a class="toctext" href="../../10/m10.02d1/">m10.02d1</a></li><li><a class="toctext" href="../../10/m10.04d/">m10.04d</a></li></ul></li><li><span class="toctext">Chapter 12</span><ul><li><a class="toctext" href="../m12.6d/">m12.6d</a></li><li class="current"><a class="toctext" href>m12.6d1</a><ul class="internal"></ul></li></ul></li><li><a class="toctext" href="../../">Functions</a></li></ul></nav><article id="docs"><header><nav><ul><li>Chapter 12</li><li><a href>m12.6d1</a></li></ul><a class="edit-page" href="https://github.com/StatisticalRethinkingJulia/DynamicHMCModels.jl/blob/master/scripts/12/m12.6d1.jl"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>m12.6d1</span><a class="fa fa-bars" href="#"></a></div></header><div><pre><code class="language-julia">using DynamicHMCModels

ProjDir = rel_path_d(&quot;..&quot;, &quot;scripts&quot;, &quot;12&quot;)

df = CSV.read(rel_path( &quot;..&quot;, &quot;data&quot;,  &quot;Kline.csv&quot;), delim=&#39;;&#39;);
size(df) # Should be 10x5</code></pre><pre><code class="language-none">(10, 5)</code></pre></div><p>New col logpop, set log() for population data</p><div><pre><code class="language-julia">df[:society] = 1:10;
df[:logpop] = map((x) -&gt; log(x), df[:population]);
#df[:total_tools] = convert(Vector{Int64}, df[:total_tools])
first(df[[:total_tools, :logpop, :society]], 5)</code></pre><table class="data-frame"><thead><tr><th></th><th>total_tools</th><th>logpop</th><th>society</th></tr><tr><th></th><th>Int64⍰</th><th>Float64</th><th>Int64</th></tr></thead><tbody><p>5 rows × 3 columns</p><tr><th>1</th><td>13</td><td>7.00307</td><td>1</td></tr><tr><th>2</th><td>22</td><td>7.31322</td><td>2</td></tr><tr><th>3</th><td>24</td><td>8.18869</td><td>3</td></tr><tr><th>4</th><td>43</td><td>8.47449</td><td>4</td></tr><tr><th>5</th><td>33</td><td>8.90924</td><td>5</td></tr></tbody></table></div><p>Define problem data structure</p><div><pre><code class="language-julia">struct m_12_06d{TY &lt;: AbstractVector, TX &lt;: AbstractMatrix,
  TS &lt;: AbstractVector}
    &quot;Observations (total_tools).&quot;
    y::TY
    &quot;Covariates (logpop)&quot;
    X::TX
    &quot;Society&quot;
    S::TS
    &quot;Number of observations (10)&quot;
    N::Int
    &quot;Number of societies (also 10)&quot;
    N_societies::Int
end;</code></pre></div><p>Make the type callable with the parameters <em>as a single argument</em>.</p><div><pre><code class="language-julia">function (problem::m_12_06d)(θ)
    @unpack y, X, S, N, N_societies = problem   # extract the data
    @unpack β, α, s = trans(θ)  # β : a, bp, α : a_society, s
    σ = s[1]^2
    ll = 0.0
    ll += logpdf(Cauchy(0, 1), σ) # sigma
    ll += sum(logpdf.(Normal(0, σ), α)) # α[1:10]
    ll += logpdf.(Normal(0, 10), β[1]) # a
    ll += logpdf.(Normal(0, 1), β[2]) # bp
    ll += sum(
      [loglikelihood(Poisson(exp(α[S[i]] + dot(X[i, :], β))), [y[i]]) for i in 1:N]
    )
end</code></pre></div><p>Instantiate the model with data and inits.</p><div><pre><code class="language-julia">N = size(df, 1)
N_societies = length(unique(df[:society]))
X = hcat(ones(Int64, N), df[:logpop]);
S = df[:society];
y = df[:total_tools];
γ = (β = [1.0, 0.25], α = rand(Normal(0, 1), N_societies), s = [0.2]);
p = m_12_06d(y, X, S, N, N_societies);</code></pre><pre><code class="language-none">Main.ex-m12.6d1.m_12_06d{Array{Union{Missing, Int64},1},Array{Float64,2},Array{Int64,1}}(Union{Missing, Int64}[13, 22, 24, 43, 33, 19, 40, 28, 55, 71], [1.0 7.00307; 1.0 7.31322; … ; 1.0 9.76996; 1.0 12.5245], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 10, 10)</code></pre></div><p>Function convert from a single vector of parms to parks NamedTuple</p><div><pre><code class="language-julia">trans = as((β = as(Array, 2), α = as(Array, 10), s = as(Array, 1)));</code></pre><pre><code class="language-none">TransformVariables.TransformNamedTuple{(:β, :α, :s),Tuple{TransformVariables.ArrayTransform{TransformVariables.Identity,1},TransformVariables.ArrayTransform{TransformVariables.Identity,1},TransformVariables.ArrayTransform{TransformVariables.Identity,1}}}((TransformVariables.ArrayTransform{TransformVariables.Identity,1}(TransformVariables.Identity(), (2,)), TransformVariables.ArrayTransform{TransformVariables.Identity,1}(TransformVariables.Identity(), (10,)), TransformVariables.ArrayTransform{TransformVariables.Identity,1}(TransformVariables.Identity(), (1,))), 13)</code></pre></div><p>Define input parameter vector</p><div><pre><code class="language-julia">θ = inverse(trans, γ);
p(θ)</code></pre><pre><code class="language-none">-1912.3664713742312</code></pre></div><p>Maximum<em>a</em>posterior</p><div><pre><code class="language-julia">using Optim

x0 = θ;
lower = vcat([0.0, 0.0], -3ones(10), [0.0]);
upper = vcat([2.0, 1.0], 3ones(10), [5.0]);
ll(x) = -p(x);

inner_optimizer = GradientDescent()

res = optimize(ll, lower, upper, x0, Fminbox(inner_optimizer));
res</code></pre><pre><code class="language-none">Results of Optimization Algorithm
 * Algorithm: Fminbox with Gradient Descent
 * Starting Point: [1.0,0.25, ...]
 * Minimizer: [1.0972715548274445,0.263085952539797, ...]
 * Minimum: -1.354108e+02
 * Iterations: 1000
 * Convergence: false
   * |x - x&#39;| ≤ 0.0e+00: false
     |x - x&#39;| = 8.58e-11
   * |f(x) - f(x&#39;)| ≤ 0.0e+00 |f(x)|: false
     |f(x) - f(x&#39;)| = -1.63e-07 |f(x)|
   * |g(x)| ≤ 1.0e-08: false
     |g(x)| = 2.58e+05
   * Stopped by an increasing objective: false
   * Reached Maximum Number of Iterations: false
 * Objective Calls: 906111312
 * Gradient Calls: 906111312</code></pre></div><p>Minimum gives MAP estimate:</p><div><pre><code class="language-julia">Optim.minimizer(res)</code></pre><pre><code class="language-none">13-element Array{Float64,1}:
  1.0972715548274445
  0.263085952539797
 -1.453041991637109e-13
  9.018779591473765e-15
 -7.814659653729915e-14
  2.781582812909403e-13
 -2.525441579421861e-14
 -3.437224446759815e-13
  7.480126782969005e-14
 -2.738193485119261e-13
  2.1810049870602713e-13
 -3.515488797026077e-12
  7.772900447995459e-5</code></pre></div><p>Write a function to return properly dimensioned transformation.</p><div><pre><code class="language-julia">problem_transformation(p::m_12_06d) =
  as( Vector, length(θ) )</code></pre></div><p>Wrap the problem with a transformation, then use ForwardDiff for the gradient.</p><div><pre><code class="language-julia">P = TransformedLogDensity(problem_transformation(p), p)
∇P = LogDensityRejectErrors(ADgradient(:ForwardDiff, P));
#∇P = ADgradient(:ForwardDiff, P);</code></pre></div><p>Tune and sample.</p><div><pre><code class="language-julia">chain, NUTS_tuned = NUTS_init_tune_mcmc(∇P, 1000);</code></pre><pre><code class="language-none">MCMC, adapting ϵ (75 steps)
0.0059 s/step ...done
MCMC, adapting ϵ (25 steps)
0.0029 s/step ...done
MCMC, adapting ϵ (50 steps)
0.0095 s/step ...done
MCMC, adapting ϵ (100 steps)
0.0018 s/step ...done
MCMC, adapting ϵ (200 steps)
0.0016 s/step ...done
MCMC, adapting ϵ (400 steps)
0.00091 s/step ...done
MCMC, adapting ϵ (50 steps)
0.00098 s/step ...done
MCMC (1000 steps)
0.00076 s/step ...done
(NUTS_Transition{Array{Float64,1},Float64}[NUTS_Transition{Array{Float64,1},Float64}([0.0495356, 0.376957, -0.11578, 0.29468, -0.0202731, 0.458217, 0.308019, -0.221391, -0.00475582, -0.0983277, 0.376659, -0.464636, -0.478951], -41.9733, 4, DoubledTurn, 0.967823, 15), NUTS_Transition{Array{Float64,1},Float64}([1.48843, 0.223915, -0.239376, -0.0355471, 0.0561079, 0.170846, 0.20938, -0.691616, 0.1927, -0.321477, 0.549863, 0.0960973, -0.528678], -46.046, 4, DoubledTurn, 0.86572, 15), NUTS_Transition{Array{Float64,1},Float64}([0.16107, 0.350733, -0.0626365, 0.440562, 0.0318514, 0.342177, 0.0469811, -0.0364473, 0.333862, -0.0224782, 0.230746, -0.161823, -0.548918], -45.8759, 4, DoubledTurn, 0.997514, 15), NUTS_Transition{Array{Float64,1},Float64}([1.71893, 0.196526, -0.195245, -0.191326, 0.0161352, 0.336949, 0.11793, -0.448298, 0.048372, -0.233998, 0.400861, -0.0550734, -0.539712], -41.6254, 4, DoubledTurn, 0.920416, 15), NUTS_Transition{Array{Float64,1},Float64}([2.03819, 0.159184, -0.266736, -0.212017, -0.0609277, 0.536942, -0.0390547, -0.189295, 0.0638614, -0.236403, 0.201976, 0.010527, -0.405883], -44.6628, 4, DoubledTurn, 0.881835, 15), NUTS_Transition{Array{Float64,1},Float64}([0.844323, 0.289903, -0.15378, 0.12418, -0.0532818, 0.0866408, -0.135317, -0.279937, 0.348725, -0.164629, 0.397099, -0.056325, -0.439293], -44.0754, 4, DoubledTurn, 0.949261, 15), NUTS_Transition{Array{Float64,1},Float64}([0.933739, 0.275746, -0.0841962, 0.102485, -0.0470086, 0.058276, -0.174347, -0.200861, 0.387572, -0.163477, 0.3853, -0.0845071, -0.455903], -43.4067, 4, DoubledTurn, 0.972463, 15), NUTS_Transition{Array{Float64,1},Float64}([1.40077, 0.216246, -0.138407, -0.0806576, 0.119588, 0.204908, 0.282949, -0.197603, 0.0920228, -0.162206, 0.043102, 0.141447, -0.506185], -45.5053, 4, DoubledTurn, 0.771806, 15), NUTS_Transition{Array{Float64,1},Float64}([0.676075, 0.303166, -0.119132, 0.092966, -0.164669, 0.202058, -0.0762861, -0.207337, 0.176505, -0.130183, 0.0728974, -0.215117, -0.348804], -41.2873, 4, DoubledTurn, 0.995242, 15), NUTS_Transition{Array{Float64,1},Float64}([1.36656, 0.214355, -0.133175, 0.0383571, 0.141995, 0.321854, 0.0426383, -0.259007, 0.272277, -0.0493314, 0.60259, 0.136786, -0.579669], -39.1201, 4, DoubledTurn, 0.960451, 15)  …  NUTS_Transition{Array{Float64,1},Float64}([-0.0237024, 0.389267, -0.431072, 0.447748, -0.291489, 0.08646, -0.119769, -0.453719, 0.0521748, -0.0550211, 0.351262, -0.248727, -0.509941], -52.5872, 4, DoubledTurn, 0.875715, 15), NUTS_Transition{Array{Float64,1},Float64}([2.51578, 0.120834, 0.112467, -0.323047, 0.0253146, 0.323139, 0.106654, -0.117939, 0.147234, -0.3925, 0.1701, 0.102288, -0.432496], -49.6937, 4, DoubledTurn, 0.997283, 15), NUTS_Transition{Array{Float64,1},Float64}([2.04888, 0.144604, -0.137795, 0.0532879, -0.103577, 0.329099, 0.0950092, -0.0329344, -0.0224355, -0.0352759, 0.423443, 0.249878, -0.600817], -52.2992, 4, DoubledTurn, 0.958696, 15), NUTS_Transition{Array{Float64,1},Float64}([0.472087, 0.309866, -0.308176, 0.0604532, 0.131284, 0.564785, 0.224533, -0.579238, 0.516694, -0.0443439, 0.420099, -0.134094, -0.624759], -45.9563, 4, DoubledTurn, 0.947524, 15), NUTS_Transition{Array{Float64,1},Float64}([0.397536, 0.311558, 0.190739, 0.166578, 0.345717, 0.68162, 0.191431, -0.419289, 0.502798, 0.11352, 0.563619, -0.0283511, -0.586573], -44.3723, 4, DoubledTurn, 0.848812, 15), NUTS_Transition{Array{Float64,1},Float64}([1.44512, 0.241895, -0.463534, -0.0784584, -0.283248, -0.040636, -0.084486, -0.282542, -0.227306, -0.141562, 0.0377717, -0.149882, -0.422118], -44.0152, 4, DoubledTurn, 0.991231, 15), NUTS_Transition{Array{Float64,1},Float64}([0.517191, 0.323258, -0.237576, 0.218123, -0.112123, 0.558819, -0.0579329, -0.453402, 0.165115, -0.0605358, 0.233295, -0.149808, -0.600078], -47.8706, 3, AdjacentTurn, 0.63397, 15), NUTS_Transition{Array{Float64,1},Float64}([0.840299, 0.275018, -0.0989041, 0.0365925, -0.123967, 0.643893, -0.00322738, -0.120642, 0.277585, 0.0624452, 0.197749, 0.0989172, -0.473982], -42.7934, 3, DoubledTurn, 0.682909, 7), NUTS_Transition{Array{Float64,1},Float64}([0.656727, 0.31444, 0.205863, -0.129936, 0.0729749, 0.306297, 0.00140482, -0.586688, 0.178113, -0.258675, 0.238261, -0.309971, -0.62739], -43.317, 4, DoubledTurn, 0.962888, 15), NUTS_Transition{Array{Float64,1},Float64}([3.02321, 0.0691707, -0.732951, -0.225459, -0.179056, 0.247955, -0.271938, -0.667896, 0.0879769, -0.325762, 0.382388, 0.268634, -0.71512], -47.1044, 4, DoubledTurn, 0.902954, 15)], NUTS sampler in 13 dimensions
  stepsize (ϵ) ≈ 0.259
  maximum depth = 10
  Gaussian kinetic energy, √diag(M⁻¹): [0.716282, 0.0814658, 0.24025, 0.203757, 0.20184, 0.187404, 0.173765, 0.219047, 0.16588, 0.194496, 0.16997, 0.295819, 0.118809]
)</code></pre></div><p>We use the transformation to obtain the posterior from the chain.</p><div><pre><code class="language-julia">posterior = TransformVariables.transform.(Ref(problem_transformation(p)), get_position.(chain));
posterior[1:5]</code></pre><pre><code class="language-none">5-element Array{Array{Float64,1},1}:
 [0.0495356, 0.376957, -0.11578, 0.29468, -0.0202731, 0.458217, 0.308019, -0.221391, -0.00475582, -0.0983277, 0.376659, -0.464636, -0.478951]
 [1.48843, 0.223915, -0.239376, -0.0355471, 0.0561079, 0.170846, 0.20938, -0.691616, 0.1927, -0.321477, 0.549863, 0.0960973, -0.528678]
 [0.16107, 0.350733, -0.0626365, 0.440562, 0.0318514, 0.342177, 0.0469811, -0.0364473, 0.333862, -0.0224782, 0.230746, -0.161823, -0.548918]
 [1.71893, 0.196526, -0.195245, -0.191326, 0.0161352, 0.336949, 0.11793, -0.448298, 0.048372, -0.233998, 0.400861, -0.0550734, -0.539712]
 [2.03819, 0.159184, -0.266736, -0.212017, -0.0609277, 0.536942, -0.0390547, -0.189295, 0.0638614, -0.236403, 0.201976, 0.010527, -0.405883]</code></pre></div><p>Extract the parameter posterior means.</p><div><pre><code class="language-julia">posterior_β = mean(trans(posterior[i]).β for i in 1:length(posterior))
posterior_α = mean(trans(posterior[i]).α for i in 1:length(posterior))
posterior_σ = mean(trans(posterior[i]).s for i in 1:length(posterior))[1]^2</code></pre><pre><code class="language-none">0.27893830226212896</code></pre></div><p>Effective sample sizes (of untransformed draws)</p><div><pre><code class="language-julia">ess = mapslices(effective_sample_size, get_position_matrix(chain); dims = 1)
ess</code></pre><pre><code class="language-none">1×13 Array{Float64,2}:
 1000.0  967.495  799.916  1000.0  …  1000.0  990.786  946.621  530.487</code></pre></div><p>NUTS-specific statistics</p><div><pre><code class="language-julia">NUTS_statistics(chain)</code></pre><pre><code class="language-none">Hamiltonian Monte Carlo sample of length 1000
  acceptance rate mean: 0.91, min/25%/median/75%/max: 0.19 0.87 0.95 0.99 1.0
  termination: AdjacentTurn =&gt; 7% DoubledTurn =&gt; 93%
  depth: 1 =&gt; 0% 2 =&gt; 0% 3 =&gt; 11% 4 =&gt; 89%</code></pre></div><p>CmdStan result</p><div><pre><code class="language-julia">m_12_6_result = &quot;
Iterations = 1:1000
Thinning interval = 1
Chains = 1,2,3,4
Samples per chain = 1000

Empirical Posterior Estimates:
                            Mean                SD               Naive SE             MCSE            ESS
            a          1.076167468  0.7704872560 0.01218247319 0.0210530022 1000.000000
           bp         0.263056273  0.0823415805 0.00130193470 0.0022645077 1000.000000
  a_society.1   -0.191723568  0.2421382537 0.00382854195 0.0060563054 1000.000000
  a_society.2    0.054569029  0.2278506876 0.00360263570 0.0051693148 1000.000000
  a_society.3   -0.035935050  0.1926364647 0.00304584994 0.0039948433 1000.000000
  a_society.4    0.334355037  0.1929971201 0.00305155241 0.0063871707  913.029080
  a_society.5    0.049747513  0.1801287716 0.00284808595 0.0043631095 1000.000000
  a_society.6   -0.311903245  0.2096126337 0.00331426674 0.0053000536 1000.000000
  a_society.7    0.148637507  0.1744680594 0.00275858223 0.0047660246 1000.000000
  a_society.8   -0.164567976  0.1821341074 0.00287979309 0.0034297298 1000.000000
  a_society.9    0.277066965  0.1758237250 0.00278001719 0.0055844175  991.286501
 a_society.10   -0.094149204  0.2846206232 0.00450024719 0.0080735022 1000.000000
sigma_society    0.310352849  0.1374834682 0.00217380450 0.0057325226  575.187461
&quot;;</code></pre><pre><code class="language-none">&quot;\nIterations = 1:1000\nThinning interval = 1\nChains = 1,2,3,4\nSamples per chain = 1000\n\nEmpirical Posterior Estimates:\n                            Mean                SD               Naive SE             MCSE            ESS\n            a          1.076167468  0.7704872560 0.01218247319 0.0210530022 1000.000000\n           bp         0.263056273  0.0823415805 0.00130193470 0.0022645077 1000.000000\n  a_society.1   -0.191723568  0.2421382537 0.00382854195 0.0060563054 1000.000000\n  a_society.2    0.054569029  0.2278506876 0.00360263570 0.0051693148 1000.000000\n  a_society.3   -0.035935050  0.1926364647 0.00304584994 0.0039948433 1000.000000\n  a_society.4    0.334355037  0.1929971201 0.00305155241 0.0063871707  913.029080\n  a_society.5    0.049747513  0.1801287716 0.00284808595 0.0043631095 1000.000000\n  a_society.6   -0.311903245  0.2096126337 0.00331426674 0.0053000536 1000.000000\n  a_society.7    0.148637507  0.1744680594 0.00275858223 0.0047660246 1000.000000\n  a_society.8   -0.164567976  0.1821341074 0.00287979309 0.0034297298 1000.000000\n  a_society.9    0.277066965  0.1758237250 0.00278001719 0.0055844175  991.286501\n a_society.10   -0.094149204  0.2846206232 0.00450024719 0.0080735022 1000.000000\nsigma_society    0.310352849  0.1374834682 0.00217380450 0.0057325226  575.187461\n&quot;</code></pre></div><p>Show means</p><div><pre><code class="language-julia">[posterior_β, posterior_α, posterior_σ]</code></pre><pre><code class="language-none">3-element Array{Any,1}:
  [1.13225, 0.257033]
  [-0.1967, 0.0516497, -0.0451368, 0.31843, 0.0442222, -0.299275, 0.148154, -0.15832, 0.274576, -0.0725005]
 0.27893830226212896</code></pre></div><p>End of m12.6d1.jl</p><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p><footer><hr/><a class="previous" href="../m12.6d/"><span class="direction">Previous</span><span class="title">m12.6d</span></a><a class="next" href="../../"><span class="direction">Next</span><span class="title">Functions</span></a></footer></article></body></html>
