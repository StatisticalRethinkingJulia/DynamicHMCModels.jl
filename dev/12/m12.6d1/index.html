<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>m12.6d1 · DynamicHMCModels.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link href="../../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>DynamicHMCModels.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../../intro/">Home</a></li><li><span class="toctext">Chapter 02</span><ul><li><a class="toctext" href="../../02/m2.1d/">m2.1d</a></li></ul></li><li><span class="toctext">Chapter 04</span><ul><li><a class="toctext" href="../../04/m4.1d/">m4.1d</a></li><li><a class="toctext" href="../../04/m4.2d/">m4.2d</a></li><li><a class="toctext" href="../../04/m4.5d/">m4.5d</a></li></ul></li><li><span class="toctext">Chapter 05</span><ul><li><a class="toctext" href="../../05/m5.1d/">m5.1d</a></li><li><a class="toctext" href="../../05/m5.1d1/">m5.1d1</a></li><li><a class="toctext" href="../../05/m5.3d/">m5.3d</a></li><li><a class="toctext" href="../../05/m5.6d/">m5.6d</a></li></ul></li><li><span class="toctext">Chapter 08</span><ul><li><a class="toctext" href="../../08/m8.1d/">m8.1d</a></li></ul></li><li><span class="toctext">Chapter 10</span><ul><li><a class="toctext" href="../../10/m10.02d/">m10.02d</a></li><li><a class="toctext" href="../../10/m10.02d1/">m10.02d1</a></li><li><a class="toctext" href="../../10/m10.04d/">m10.04d</a></li></ul></li><li><span class="toctext">Chapter 12</span><ul><li><a class="toctext" href="../m12.6d/">m12.6d</a></li><li class="current"><a class="toctext" href>m12.6d1</a><ul class="internal"></ul></li></ul></li><li><a class="toctext" href="../../">Functions</a></li></ul></nav><article id="docs"><header><nav><ul><li>Chapter 12</li><li><a href>m12.6d1</a></li></ul><a class="edit-page" href="https://github.com/StatisticalRethinkingJulia/DynamicHMCModels.jl/blob/master/scripts/12/m12.6d1.jl"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>m12.6d1</span><a class="fa fa-bars" href="#"></a></div></header><div><pre><code class="language-julia">using DynamicHMCModels

ProjDir = rel_path_d(&quot;..&quot;, &quot;scripts&quot;, &quot;12&quot;)

df = CSV.read(rel_path( &quot;..&quot;, &quot;data&quot;,  &quot;Kline.csv&quot;), delim=&#39;;&#39;);
size(df) # Should be 10x5</code></pre><pre><code class="language-none">(10, 5)</code></pre></div><p>New col logpop, set log() for population data</p><div><pre><code class="language-julia">df[:society] = 1:10;
df[:logpop] = map((x) -&gt; log(x), df[:population]);
#df[:total_tools] = convert(Vector{Int64}, df[:total_tools])
first(df[[:total_tools, :logpop, :society]], 5)</code></pre><table class="data-frame"><thead><tr><th></th><th>total_tools</th><th>logpop</th><th>society</th></tr><tr><th></th><th>Int64⍰</th><th>Float64</th><th>Int64</th></tr></thead><tbody><p>5 rows × 3 columns</p><tr><th>1</th><td>13</td><td>7.00307</td><td>1</td></tr><tr><th>2</th><td>22</td><td>7.31322</td><td>2</td></tr><tr><th>3</th><td>24</td><td>8.18869</td><td>3</td></tr><tr><th>4</th><td>43</td><td>8.47449</td><td>4</td></tr><tr><th>5</th><td>33</td><td>8.90924</td><td>5</td></tr></tbody></table></div><p>Define problem data structure</p><div><pre><code class="language-julia">struct m_12_06d{TY &lt;: AbstractVector, TX &lt;: AbstractMatrix,
  TS &lt;: AbstractVector}
    &quot;Observations (total_tools).&quot;
    y::TY
    &quot;Covariates (logpop)&quot;
    X::TX
    &quot;Society&quot;
    S::TS
    &quot;Number of observations (10)&quot;
    N::Int
    &quot;Number of societies (also 10)&quot;
    N_societies::Int
end;</code></pre></div><p>Make the type callable with the parameters <em>as a single argument</em>.</p><div><pre><code class="language-julia">function (problem::m_12_06d)(θ)
    @unpack y, X, S, N, N_societies = problem   # extract the data
    @unpack β, α, s = trans(θ)  # β : a, bp, α : a_society, s
    σ = s[1]^2
    ll = 0.0
    ll += logpdf(Cauchy(0, 1), σ) # sigma
    ll += sum(logpdf.(Normal(0, σ), α)) # α[1:10]
    ll += logpdf.(Normal(0, 10), β[1]) # a
    ll += logpdf.(Normal(0, 1), β[2]) # bp
    ll += sum(
      [loglikelihood(Poisson(exp(α[S[i]] + dot(X[i, :], β))), [y[i]]) for i in 1:N]
    )
end</code></pre></div><p>Instantiate the model with data and inits.</p><div><pre><code class="language-julia">N = size(df, 1)
N_societies = length(unique(df[:society]))
X = hcat(ones(Int64, N), df[:logpop]);
S = df[:society];
y = df[:total_tools];
γ = (β = [1.0, 0.25], α = rand(Normal(0, 1), N_societies), s = [0.2]);
p = m_12_06d(y, X, S, N, N_societies);</code></pre><pre><code class="language-none">Main.ex-m12.6d1.m_12_06d{Array{Union{Missing, Int64},1},Array{Float64,2},Array{Int64,1}}(Union{Missing, Int64}[13, 22, 24, 43, 33, 19, 40, 28, 55, 71], [1.0 7.00307; 1.0 7.31322; … ; 1.0 9.76996; 1.0 12.5245], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 10, 10)</code></pre></div><p>Function convert from a single vector of parms to parks NamedTuple</p><div><pre><code class="language-julia">trans = as((β = as(Array, 2), α = as(Array, 10), s = as(Array, 1)));</code></pre><pre><code class="language-none">TransformVariables.TransformNamedTuple{(:β, :α, :s),Tuple{TransformVariables.ArrayTransform{TransformVariables.Identity,1},TransformVariables.ArrayTransform{TransformVariables.Identity,1},TransformVariables.ArrayTransform{TransformVariables.Identity,1}}}((TransformVariables.ArrayTransform{TransformVariables.Identity,1}(TransformVariables.Identity(), (2,)), TransformVariables.ArrayTransform{TransformVariables.Identity,1}(TransformVariables.Identity(), (10,)), TransformVariables.ArrayTransform{TransformVariables.Identity,1}(TransformVariables.Identity(), (1,))), 13)</code></pre></div><p>Define input parameter vector</p><div><pre><code class="language-julia">θ = inverse(trans, γ);
p(θ)</code></pre><pre><code class="language-none">-4465.757843186431</code></pre></div><p>Maximum<em>a</em>posterior</p><div><pre><code class="language-julia">using Optim

x0 = θ;
lower = vcat([0.0, 0.0], -3ones(10), [0.0]);
upper = vcat([2.0, 1.0], 3ones(10), [5.0]);
ll(x) = -p(x);

inner_optimizer = GradientDescent()

res = optimize(ll, lower, upper, x0, Fminbox(inner_optimizer));
res</code></pre><pre><code class="language-none">Results of Optimization Algorithm
 * Algorithm: Fminbox with Gradient Descent
 * Starting Point: [1.0,0.25, ...]
 * Minimizer: [1.0737282680464502,0.2655612662491339, ...]
 * Minimum: -1.313707e+02
 * Iterations: 1000
 * Convergence: false
   * |x - x&#39;| ≤ 0.0e+00: false
     |x - x&#39;| = 2.03e-11
   * |f(x) - f(x&#39;)| ≤ 0.0e+00 |f(x)|: false
     |f(x) - f(x&#39;)| = -1.44e-07 |f(x)|
   * |g(x)| ≤ 1.0e-08: false
     |g(x)| = 7.25e+05
   * Stopped by an increasing objective: false
   * Reached Maximum Number of Iterations: false
 * Objective Calls: 521605629
 * Gradient Calls: 521605629</code></pre></div><p>Minimum gives MAP estimate:</p><div><pre><code class="language-julia">Optim.minimizer(res)</code></pre><pre><code class="language-none">13-element Array{Float64,1}:
  1.0737282680464502
  0.2655612662491339
  4.565734198307936e-12
 -1.5894301454747436e-12
  1.000329043878494e-12
 -1.3129529046747764e-11
 -2.216463565488889e-12
  9.867914007828907e-12
 -6.588881189558656e-12
  5.723313671063143e-12
 -1.4433714030773136e-11
 -5.866019772006112e-11
  9.48303121164297e-5</code></pre></div><p>Write a function to return properly dimensioned transformation.</p><div><pre><code class="language-julia">problem_transformation(p::m_12_06d) =
  as( Vector, length(θ) )</code></pre></div><p>Wrap the problem with a transformation, then use ForwardDiff for the gradient.</p><div><pre><code class="language-julia">P = TransformedLogDensity(problem_transformation(p), p)
∇P = LogDensityRejectErrors(ADgradient(:ForwardDiff, P));
#∇P = ADgradient(:ForwardDiff, P);</code></pre></div><p>Tune and sample.</p><div><pre><code class="language-julia">chain, NUTS_tuned = NUTS_init_tune_mcmc(∇P, 1000);</code></pre><pre><code class="language-none">MCMC, adapting ϵ (75 steps)
0.0066 s/step ...done
MCMC, adapting ϵ (25 steps)
0.0068 s/step ...done
MCMC, adapting ϵ (50 steps)
0.0083 s/step ...done
MCMC, adapting ϵ (100 steps)
0.0031 s/step ...done
MCMC, adapting ϵ (200 steps)
0.0016 s/step ...done
MCMC, adapting ϵ (400 steps)
0.0011 s/step ...done
MCMC, adapting ϵ (50 steps)
0.0012 s/step ...done
MCMC (1000 steps)
0.00074 s/step ...done
(NUTS_Transition{Array{Float64,1},Float64}[NUTS_Transition{Array{Float64,1},Float64}([1.94649, 0.158257, -0.159769, 0.110044, 0.050984, 0.577613, 0.169092, -0.221008, 0.195988, 0.00673574, 0.391257, 0.136789, 0.50482], -40.5765, 3, DoubledTurn, 0.924951, 7), NUTS_Transition{Array{Float64,1},Float64}([0.238534, 0.326187, 0.164205, 0.518332, 0.19767, 0.595424, 0.319954, 0.00871166, 0.3273, 0.14269, 0.462103, -0.0922999, 0.683636], -46.599, 4, DoubledTurn, 0.937934, 15), NUTS_Transition{Array{Float64,1},Float64}([1.12313, 0.227138, -0.253216, 0.294872, 0.177114, 0.690684, 0.443537, -0.135172, 0.587485, -0.0188665, 0.741344, 0.272326, 0.595107], -44.4717, 4, DoubledTurn, 0.973601, 15), NUTS_Transition{Array{Float64,1},Float64}([0.800604, 0.282163, 0.0652, 0.285593, 0.216655, 0.441753, 0.24807, -0.324378, 0.481445, -0.0601491, 0.372154, -0.00825771, 0.556347], -41.8729, 4, DoubledTurn, 0.936263, 15), NUTS_Transition{Array{Float64,1},Float64}([1.24991, 0.218641, 0.175174, 0.158483, 0.212025, 0.387083, 0.295225, -0.343508, 0.617437, 0.0127479, 0.383019, 0.117991, 0.444259], -46.6182, 3, DoubledTurn, 0.874145, 7), NUTS_Transition{Array{Float64,1},Float64}([1.81417, 0.201981, -0.68948, -0.239155, -0.210119, 0.153883, -0.0438358, -0.105449, -0.331427, -0.17577, 0.119137, -0.0357905, 0.479573], -50.7935, 4, DoubledTurn, 0.895523, 15), NUTS_Transition{Array{Float64,1},Float64}([0.788425, 0.325871, -0.572606, -0.00764989, -0.459982, 0.0103946, -0.0623407, -0.625763, 0.114909, -0.414222, 0.172469, -0.638279, 0.778098], -50.0223, 4, DoubledTurn, 0.998304, 15), NUTS_Transition{Array{Float64,1},Float64}([0.357968, 0.359313, -0.274575, 0.406768, -0.0259601, 0.201978, -0.128699, -0.792133, 0.033078, -0.339798, 0.147683, -0.559208, 0.616443], -48.9746, 4, DoubledTurn, 0.958197, 15), NUTS_Transition{Array{Float64,1},Float64}([1.56068, 0.199049, -0.183364, 0.112868, -0.0128415, 0.350545, -0.0761934, 0.207282, 0.167391, -0.154956, 0.33929, 0.18474, 0.403179], -43.7525, 4, DoubledTurn, 0.972413, 15), NUTS_Transition{Array{Float64,1},Float64}([0.620711, 0.304982, -0.292444, 0.21711, -0.10952, 0.475772, 0.237448, -0.453909, -0.0822283, 0.000219261, 0.291914, -0.27337, 0.615906], -44.0653, 4, DoubledTurn, 0.852201, 15)  …  NUTS_Transition{Array{Float64,1},Float64}([1.48255, 0.222783, -0.0651877, 0.163681, -0.332258, 0.166616, 0.0224353, -0.205281, 0.133798, -0.161015, 0.299989, -0.172431, 0.412209], -44.0513, 4, DoubledTurn, 0.911478, 15), NUTS_Transition{Array{Float64,1},Float64}([1.34613, 0.246475, -0.224529, 0.00617767, 0.0573581, 0.21595, -0.129956, -0.335184, -0.0303377, -0.199151, 0.148405, -0.216032, 0.495136], -39.5486, 4, DoubledTurn, 0.911122, 15), NUTS_Transition{Array{Float64,1},Float64}([0.576957, 0.32507, -0.172327, 0.135544, 0.0532316, 0.137012, 0.0350736, -0.525181, -0.0128235, -0.0200937, 0.233764, -0.387288, 0.579451], -45.0163, 4, DoubledTurn, 0.872759, 15), NUTS_Transition{Array{Float64,1},Float64}([1.47837, 0.236428, -0.257407, -0.0203594, -0.0194458, -0.0264518, 0.0169837, -0.457236, -0.0292261, 0.0354087, 0.276067, -0.166779, 0.531896], -42.2345, 4, DoubledTurn, 0.875038, 15), NUTS_Transition{Array{Float64,1},Float64}([0.924686, 0.299429, -0.0564297, -0.14729, -0.188754, 0.182328, -0.168038, -0.335743, -0.181965, -0.17789, 0.275936, -0.336631, 0.498336], -41.4164, 4, DoubledTurn, 1.0, 15), NUTS_Transition{Array{Float64,1},Float64}([0.751779, 0.301224, -0.188264, 0.39548, 0.011693, 0.375744, 0.200093, -0.279362, 0.327051, -0.202618, 0.241722, -0.153355, 0.433357], -42.0118, 4, DoubledTurn, 0.909935, 15), NUTS_Transition{Array{Float64,1},Float64}([0.794682, 0.291636, -0.359384, 0.232576, -0.151694, 0.362881, 0.142422, -0.295223, 0.25963, -0.15437, 0.242364, -0.257291, 0.555202], -38.3392, 3, AdjacentTurn, 1.0, 15), NUTS_Transition{Array{Float64,1},Float64}([1.04583, 0.266811, -0.118384, -0.0960164, 0.0379598, 0.292899, -0.0624098, -0.0873667, -0.0482413, 0.120079, 0.0132216, -0.0221841, 0.319407], -42.3578, 3, AdjacentTurn, 0.97711, 15), NUTS_Transition{Array{Float64,1},Float64}([1.2686, 0.248435, -0.206906, 0.00623081, -0.00843555, 0.196351, -0.034374, -0.134808, 0.0321908, -0.0949887, 0.120613, -0.0490748, 0.360783], -36.0223, 3, DoubledTurn, 1.0, 7), NUTS_Transition{Array{Float64,1},Float64}([0.975882, 0.269045, 0.0470601, 0.021174, -0.063239, 0.13392, 0.0145926, -0.269081, -0.0546718, -0.143341, 0.124409, -0.0316273, 0.375314], -36.2673, 3, DoubledTurn, 0.758707, 7)], NUTS sampler in 13 dimensions
  stepsize (ϵ) ≈ 0.292
  maximum depth = 10
  Gaussian kinetic energy, √diag(M⁻¹): [0.626054, 0.0693645, 0.198542, 0.182358, 0.162628, 0.179359, 0.14946, 0.200576, 0.165442, 0.172748, 0.15917, 0.213949, 0.12735]
)</code></pre></div><p>We use the transformation to obtain the posterior from the chain.</p><div><pre><code class="language-julia">posterior = TransformVariables.transform.(Ref(problem_transformation(p)), get_position.(chain));
posterior[1:5]</code></pre><pre><code class="language-none">5-element Array{Array{Float64,1},1}:
 [1.94649, 0.158257, -0.159769, 0.110044, 0.050984, 0.577613, 0.169092, -0.221008, 0.195988, 0.00673574, 0.391257, 0.136789, 0.50482]
 [0.238534, 0.326187, 0.164205, 0.518332, 0.19767, 0.595424, 0.319954, 0.00871166, 0.3273, 0.14269, 0.462103, -0.0922999, 0.683636]
 [1.12313, 0.227138, -0.253216, 0.294872, 0.177114, 0.690684, 0.443537, -0.135172, 0.587485, -0.0188665, 0.741344, 0.272326, 0.595107]
 [0.800604, 0.282163, 0.0652, 0.285593, 0.216655, 0.441753, 0.24807, -0.324378, 0.481445, -0.0601491, 0.372154, -0.00825771, 0.556347]
 [1.24991, 0.218641, 0.175174, 0.158483, 0.212025, 0.387083, 0.295225, -0.343508, 0.617437, 0.0127479, 0.383019, 0.117991, 0.444259]</code></pre></div><p>Extract the parameter posterior means.</p><div><pre><code class="language-julia">posterior_β = mean(trans(posterior[i]).β for i in 1:length(posterior))
posterior_α = mean(trans(posterior[i]).α for i in 1:length(posterior))
posterior_σ = mean(trans(posterior[i]).s for i in 1:length(posterior))[1]^2</code></pre><pre><code class="language-none">0.26793468817139515</code></pre></div><p>Effective sample sizes (of untransformed draws)</p><div><pre><code class="language-julia">ess = mapslices(effective_sample_size, get_position_matrix(chain); dims = 1)
ess</code></pre><pre><code class="language-none">1×13 Array{Float64,2}:
 785.539  316.279  828.369  1000.0  …  924.933  671.658  435.322  533.906</code></pre></div><p>NUTS-specific statistics</p><div><pre><code class="language-julia">NUTS_statistics(chain)</code></pre><pre><code class="language-none">Hamiltonian Monte Carlo sample of length 1000
  acceptance rate mean: 0.9, min/25%/median/75%/max: 0.0 0.86 0.94 0.98 1.0
  termination: AdjacentTurn =&gt; 6% DoubledTurn =&gt; 94%
  depth: 2 =&gt; 0% 3 =&gt; 12% 4 =&gt; 88% 5 =&gt; 0%</code></pre></div><p>CmdStan result</p><div><pre><code class="language-julia">m_12_6_result = &quot;
Iterations = 1:1000
Thinning interval = 1
Chains = 1,2,3,4
Samples per chain = 1000

Empirical Posterior Estimates:
                            Mean                SD               Naive SE             MCSE            ESS
            a          1.076167468  0.7704872560 0.01218247319 0.0210530022 1000.000000
           bp         0.263056273  0.0823415805 0.00130193470 0.0022645077 1000.000000
  a_society.1   -0.191723568  0.2421382537 0.00382854195 0.0060563054 1000.000000
  a_society.2    0.054569029  0.2278506876 0.00360263570 0.0051693148 1000.000000
  a_society.3   -0.035935050  0.1926364647 0.00304584994 0.0039948433 1000.000000
  a_society.4    0.334355037  0.1929971201 0.00305155241 0.0063871707  913.029080
  a_society.5    0.049747513  0.1801287716 0.00284808595 0.0043631095 1000.000000
  a_society.6   -0.311903245  0.2096126337 0.00331426674 0.0053000536 1000.000000
  a_society.7    0.148637507  0.1744680594 0.00275858223 0.0047660246 1000.000000
  a_society.8   -0.164567976  0.1821341074 0.00287979309 0.0034297298 1000.000000
  a_society.9    0.277066965  0.1758237250 0.00278001719 0.0055844175  991.286501
 a_society.10   -0.094149204  0.2846206232 0.00450024719 0.0080735022 1000.000000
sigma_society    0.310352849  0.1374834682 0.00217380450 0.0057325226  575.187461
&quot;;</code></pre><pre><code class="language-none">&quot;\nIterations = 1:1000\nThinning interval = 1\nChains = 1,2,3,4\nSamples per chain = 1000\n\nEmpirical Posterior Estimates:\n                            Mean                SD               Naive SE             MCSE            ESS\n            a          1.076167468  0.7704872560 0.01218247319 0.0210530022 1000.000000\n           bp         0.263056273  0.0823415805 0.00130193470 0.0022645077 1000.000000\n  a_society.1   -0.191723568  0.2421382537 0.00382854195 0.0060563054 1000.000000\n  a_society.2    0.054569029  0.2278506876 0.00360263570 0.0051693148 1000.000000\n  a_society.3   -0.035935050  0.1926364647 0.00304584994 0.0039948433 1000.000000\n  a_society.4    0.334355037  0.1929971201 0.00305155241 0.0063871707  913.029080\n  a_society.5    0.049747513  0.1801287716 0.00284808595 0.0043631095 1000.000000\n  a_society.6   -0.311903245  0.2096126337 0.00331426674 0.0053000536 1000.000000\n  a_society.7    0.148637507  0.1744680594 0.00275858223 0.0047660246 1000.000000\n  a_society.8   -0.164567976  0.1821341074 0.00287979309 0.0034297298 1000.000000\n  a_society.9    0.277066965  0.1758237250 0.00278001719 0.0055844175  991.286501\n a_society.10   -0.094149204  0.2846206232 0.00450024719 0.0080735022 1000.000000\nsigma_society    0.310352849  0.1374834682 0.00217380450 0.0057325226  575.187461\n&quot;</code></pre></div><p>Show means</p><div><pre><code class="language-julia">[posterior_β, posterior_α, posterior_σ]</code></pre><pre><code class="language-none">3-element Array{Any,1}:
  [1.11438, 0.260145]
  [-0.184143, 0.0300031, -0.0520333, 0.306832, 0.0360698, -0.300665, 0.134543, -0.162002, 0.259909, -0.0943046]
 0.26793468817139515</code></pre></div><p>End of m12.6d1.jl</p><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p><footer><hr/><a class="previous" href="../m12.6d/"><span class="direction">Previous</span><span class="title">m12.6d</span></a><a class="next" href="../../"><span class="direction">Next</span><span class="title">Functions</span></a></footer></article></body></html>
